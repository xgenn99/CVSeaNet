{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVSeaNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **How to use CVSeaNet with your own image**\n",
    "Run the \"test.ipyb\" and input the image path. The format must have the extension .tif (two-channel image)\n",
    "### **How to train CVSeaNet on your own dataset**\n",
    "Open the \"Training\" folder. Create your own dataset class and Datamodule and pass the dataset folder (.tif files) and annotations (COCO) path to the Config/Config.ini file. Then run train.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Research description and goals**\n",
    "Undesirable activities like the illegal dumping of pollutants, unauthorized fishing, human and goods trafficking and piracy require great attention from institutions. Although the Automatic Identification System continues to play a crucial role in current Vessel Monitoring Systems, transponders can be intentionally turned off, and their usage is confined to specific vessel classes and dimensions. SAR imagery offers diverse data types and imaging capabilities and its integration with maritime surveillance ensures cost-effective, global coverage, and a continuous stream of data for ship detection. Traditional algorithms, like CFAR, were prevalent in this domain, but with the emergence of Deep Learning (DL), they have been eclipsed in terms of both speed and precision. Neural Networks significantly boost the overall detection system, showcasing remarkable resilience and flexibility across diverse, intricate scenarios, thereby eliminating the requirement for segmenting between sea and land in nearshore and port environment. Current DL approaches for ship detection primarily operate on SAR image intensity rather than harnessing the complete potential of pixel complex values present in the Single Look Complex (SLC) data. Thus, the primary research objective of this work is the development of a novel ship detection Neural Network, called CVSeaNet (Complex-Valued Sea Net), which handles SAR images with complex weights and biases and not as pure intensity products. An image representation of how complex convolution is defined in Figure 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"Figures\\comp_conv.png\" alt=\"Example Plot\" width=\"500\" height=\"450\">\n",
    "    <p>Figure 1: Complex 2D Convolution.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVSeaNet is trained with a custom multi-frequency SAR SLC dataset enriched with additional information such as multiple polarizations, incidence angle, and AIS information, called Multi-frequency SAR Single Look Complex Ships (MS3). MS3 consists of SAR SLC products from three different satellite missions: SAOCOM, COSMO-SkyMed and Sentinel-1, covering different scenarios, as Egadi Islands, Sardinia and the Adriatic Sea and providing a distinct set of environments for ship detection research. A meticulous selection process for MS3 generation is based on strict temporal criteria. In this way, the appplication of multi-temporal techniques for ship detection is favored, with the introduction of an additional layer of complexity and realism to the dataset itself. Furthermore, to improve generalization and mitigate the risk of overfitting, MS3 adopts a novel data augmentation strategy (Figure 3) specifically tailored for SAR images. instead of relying on conventional augmentation techniques like random affine transformations and rotations, it generates multiple subsets of size 2048 x 2048 (Figure 2) from the same geographical area containing a vessel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:flex\">\n",
    "    <div style=\"flex:1; margin-right:10px;\">\n",
    "        <figure>\n",
    "            <img src=\"Figures\\size_img.png\" width=\"400\" height=\"400\">\n",
    "            <figcaption>Figure 2: Image sample from MS3 dataset.</figcaption>\n",
    "        </figure>\n",
    "    </div>\n",
    "    <div style=\"flex:1;\">\n",
    "        <figure>\n",
    "            <img src=\"Figures\\data_augm.png\" alt=\"Example Plot 2\" width=\"400\" height=\"400\">\n",
    "            <figcaption>Figure 3: Data augmentation strategy.</figcaption>\n",
    "        </figure>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline architecture of CVSeaNet comprises a feature extraction backbone and a prediction head. Developed in Python, through PyTorch framework and using VSCode, the backbone is inspired by EfficientNet B0 model (Figure 4), but with complex-valued layers. The head, instead, is similar to CenterNet (Figure 5), an anchor-free detector that scales down output feature maps to save memory. CVSeaNet is trained with images from MS3 dataset on a NVIDIA GeForce 3060 GPU (12 GB) with a batch size of 3, utilizing a learning rate of 1e-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:flex\">\n",
    "    <div style=\"flex:1; margin-right:10px;\">\n",
    "        <figure>\n",
    "            <img src=\"Figures\\effnet_arch.png\" width=\"400\" height=\"200\">\n",
    "            <figcaption>Figure 4: EfficientNet B0 architecture.</figcaption>\n",
    "        </figure>\n",
    "    </div>\n",
    "    <div style=\"flex:1;\">\n",
    "        <figure>\n",
    "            <img src=\"Figures\\centernet.jpg\" width=\"400\" height=\"200\">\n",
    "            <figcaption>Figure 5: CenterNet head.</figcaption>\n",
    "        </figure>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two cases are considered for results validation: CVSeaNet and the same architecture with real-valued convolution instead of complex layers. A third case is evaluated considering the same complex-valued architecture but with the late data fusion of the incidence angle. Even if the third case exhibits, as expected, an improvement in the evaluation metrics, it is not considered because it does not show significant differences compared to the complex-valued in terms of outcomes. The experimental results, conducted on CVSeaNet using the MS3 dataset, illustrate the effectiveness of the complex-valued method compared to the case in which real-valued convolution is employed considering the same architecture, showing an increase of both precision and recall (∼ 2% and ∼ 3% respectively, as shown in Figure 6). From the sample in Figure 7, CVSeaNet better performance with respect to the same architecture with real-valued convolution is demonstrated. Finally it is reasonable to affirm that the study provides a robust baseline for future research endeavors in object detection applied to maritime surveillance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"Figures\\res.png\" width=\"600\" height=\"250\">\n",
    "    <p>Figure 6: Results comparison.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"Figures\\72_preds.png\" width=\"800\" height=\"750\">\n",
    "    <p>Figure 7: Predictions comparison on a test image.</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
